{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "18d3fead-2838-4e52-8c43-5638c3901448",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "91d34b30-25d1-466e-a998-a5760ab3a040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_orig_p</th>\n",
       "      <th>id_resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>fwd_pkts_tot</th>\n",
       "      <th>bwd_pkts_tot</th>\n",
       "      <th>fwd_data_pkts_tot</th>\n",
       "      <th>bwd_data_pkts_tot</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>...</th>\n",
       "      <th>idle_min</th>\n",
       "      <th>idle_max</th>\n",
       "      <th>idle_tot</th>\n",
       "      <th>idle_avg</th>\n",
       "      <th>idle_std</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "      <th>Attack_type</th>\n",
       "      <th>Attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38667</td>\n",
       "      <td>1883</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>32.011598</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281148</td>\n",
       "      <td>...</td>\n",
       "      <td>2.972918e+07</td>\n",
       "      <td>2.972918e+07</td>\n",
       "      <td>2.972918e+07</td>\n",
       "      <td>2.972918e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240</td>\n",
       "      <td>26847</td>\n",
       "      <td>502</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51143</td>\n",
       "      <td>1883</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.883584</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.985528e+07</td>\n",
       "      <td>2.985528e+07</td>\n",
       "      <td>2.985528e+07</td>\n",
       "      <td>2.985528e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240</td>\n",
       "      <td>26847</td>\n",
       "      <td>502</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44761</td>\n",
       "      <td>1883</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>32.124053</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.280164</td>\n",
       "      <td>...</td>\n",
       "      <td>2.984215e+07</td>\n",
       "      <td>2.984215e+07</td>\n",
       "      <td>2.984215e+07</td>\n",
       "      <td>2.984215e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240</td>\n",
       "      <td>26847</td>\n",
       "      <td>502</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60893</td>\n",
       "      <td>1883</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.961063</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.281593</td>\n",
       "      <td>...</td>\n",
       "      <td>2.991377e+07</td>\n",
       "      <td>2.991377e+07</td>\n",
       "      <td>2.991377e+07</td>\n",
       "      <td>2.991377e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240</td>\n",
       "      <td>26847</td>\n",
       "      <td>502</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51087</td>\n",
       "      <td>1883</td>\n",
       "      <td>tcp</td>\n",
       "      <td>mqtt</td>\n",
       "      <td>31.902362</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.282111</td>\n",
       "      <td>...</td>\n",
       "      <td>2.981470e+07</td>\n",
       "      <td>2.981470e+07</td>\n",
       "      <td>2.981470e+07</td>\n",
       "      <td>2.981470e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64240</td>\n",
       "      <td>26847</td>\n",
       "      <td>502</td>\n",
       "      <td>MQTT_Publish</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_orig_p  id_resp_p proto service  flow_duration  fwd_pkts_tot  \\\n",
       "0      38667       1883   tcp    mqtt      32.011598             9   \n",
       "1      51143       1883   tcp    mqtt      31.883584             9   \n",
       "2      44761       1883   tcp    mqtt      32.124053             9   \n",
       "3      60893       1883   tcp    mqtt      31.961063             9   \n",
       "4      51087       1883   tcp    mqtt      31.902362             9   \n",
       "\n",
       "   bwd_pkts_tot  fwd_data_pkts_tot  bwd_data_pkts_tot  fwd_pkts_per_sec  ...  \\\n",
       "0             5                  3                  3          0.281148  ...   \n",
       "1             5                  3                  3          0.282277  ...   \n",
       "2             5                  3                  3          0.280164  ...   \n",
       "3             5                  3                  3          0.281593  ...   \n",
       "4             5                  3                  3          0.282111  ...   \n",
       "\n",
       "       idle_min      idle_max      idle_tot      idle_avg  idle_std  \\\n",
       "0  2.972918e+07  2.972918e+07  2.972918e+07  2.972918e+07       0.0   \n",
       "1  2.985528e+07  2.985528e+07  2.985528e+07  2.985528e+07       0.0   \n",
       "2  2.984215e+07  2.984215e+07  2.984215e+07  2.984215e+07       0.0   \n",
       "3  2.991377e+07  2.991377e+07  2.991377e+07  2.991377e+07       0.0   \n",
       "4  2.981470e+07  2.981470e+07  2.981470e+07  2.981470e+07       0.0   \n",
       "\n",
       "   fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \\\n",
       "0                 64240                 26847                   502   \n",
       "1                 64240                 26847                   502   \n",
       "2                 64240                 26847                   502   \n",
       "3                 64240                 26847                   502   \n",
       "4                 64240                 26847                   502   \n",
       "\n",
       "    Attack_type  Attack  \n",
       "0  MQTT_Publish  Normal  \n",
       "1  MQTT_Publish  Normal  \n",
       "2  MQTT_Publish  Normal  \n",
       "3  MQTT_Publish  Normal  \n",
       "4  MQTT_Publish  Normal  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Dataframe\n",
    "df = pd.read_csv('IOT_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6a878-91cf-4254-abf5-55eeeac84fab",
   "metadata": {},
   "source": [
    "## Encode Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9febbb54-9157-4b43-964f-8445e6e5afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "82405b48-da93-468a-850b-b27eae7b2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to categorical columns\n",
    "for column in df.columns:\n",
    "    if df[column].dtype == 'object' or df[column].dtype.name == 'category':\n",
    "        df[column] = label_encoder.fit_transform(df[column]) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "276fb030-2c82-4c35-94a4-f5bf3f8124e5",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Find out which values where mapped in Attack_type\n",
    "\n",
    "# Initialize the LabelEncoder for the specific column\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply LabelEncoder to the 'Attack_type' column\n",
    "df['Attack_type'] = label_encoder.fit_transform(df['Attack_type'])\n",
    "\n",
    "# Print the mapping for 'Attack_type'\n",
    "print(\"\\nMapping for 'Attack_type':\")\n",
    "for original, encoded in zip(label_encoder.classes_, range(len(label_encoder.classes_))):\n",
    "    print(f\"{original} -> {encoded}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "1d83dc38-01cc-4f76-8ec8-27600fd31b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 12, 10)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['proto'].nunique() , df['Attack_type'].nunique() , df['service'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b93fa-dc15-474c-8889-11e1aa3ea7d3",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3d68327c-854d-494c-b59c-d54eb388e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['Attack_type', 'Attack'])\n",
    "target = df[\"Attack_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fb25f606-2d43-4e87-908a-15068ec4c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.20, random_state=0)\n",
    "\n",
    "#Normalize Data after Train Split\n",
    "normalizer = MinMaxScaler() \n",
    "\n",
    "normalizer.fit(X_train)\n",
    "\n",
    "X_train_norm = normalizer.transform(X_train) # Normalize 80% training Data\n",
    "X_test_norm = normalizer.transform(X_test) # Normalize 20% Testing Data\n",
    "\n",
    "#Apply to test and training data\n",
    "X_train_norm = pd.DataFrame(X_train_norm, columns = X_train.columns)\n",
    "X_test_norm = pd.DataFrame(X_test_norm, columns = X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1f473326-147d-4d6f-9088-2fd3f263524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the normalized X_test data\n",
    "test_data = pd.DataFrame(X_test, columns=X_test.columns)\n",
    "\n",
    "# Save the X_test DataFrame to a CSV file\n",
    "test_data.to_csv('test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbc128-f6d5-409a-b92e-abfeb873d613",
   "metadata": {},
   "source": [
    "### Applying Smote and Undersampling on Dataframe to balance weaker class of \"Normal\" Attack_types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da0756-42b5-44fa-bbfc-e288d9793671",
   "metadata": {},
   "source": [
    "##### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "44858713-bee1-4949-b07d-152562b5dca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "0     27\n",
       "1     27\n",
       "2     27\n",
       "3     27\n",
       "4     27\n",
       "5     27\n",
       "6     27\n",
       "7     27\n",
       "8     27\n",
       "9     27\n",
       "10    27\n",
       "11    27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Apply undersampling using RandomUnderSampler\n",
    "undersampler = RandomUnderSampler(random_state=0)\n",
    "X_under, y_under = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f9438-f3a9-44b1-8ae4-6ad4592885bb",
   "metadata": {},
   "source": [
    "##### Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8990893f-0105-4673-8d2b-acdf3fc594b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "2     75705\n",
       "4     75705\n",
       "6     75705\n",
       "0     75705\n",
       "9     75705\n",
       "3     75705\n",
       "7     75705\n",
       "10    75705\n",
       "8     75705\n",
       "1     75705\n",
       "11    75705\n",
       "5     75705\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "X_smote, y_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "y_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306aaec-cf0b-4c9e-bd32-fcd36bac6d71",
   "metadata": {},
   "source": [
    "## Using Kbest to reduce number of features with Smote, Undersampling and Basedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b661158a-b282-471b-8f2f-d77e1aa4590e",
   "metadata": {},
   "source": [
    "I know I said I wont be dropping any features in wrangling, but I tried multiple variations of features before, because the models accuracy was always too good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "970ff6e7-e8d4-4227-bc96-f11ca89ad250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d189534-4dfa-44bb-b59f-13f2b526e942",
   "metadata": {},
   "source": [
    "#### Kbest for Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "215aa5a8-47bb-4ac4-be38-bd3491725b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['id_orig_p', 'proto', 'service', 'bwd_pkts_tot', 'bwd_data_pkts_tot',\n",
      "       'fwd_pkts_per_sec', 'bwd_pkts_per_sec', 'flow_pkts_per_sec',\n",
      "       'down_up_ratio', 'fwd_header_size_min', 'fwd_header_size_max',\n",
      "       'bwd_header_size_tot', 'bwd_header_size_min', 'bwd_header_size_max',\n",
      "       'flow_FIN_flag_count', 'flow_SYN_flag_count', 'flow_RST_flag_count',\n",
      "       'fwd_PSH_flag_count', 'bwd_PSH_flag_count', 'flow_ACK_flag_count',\n",
      "       'fwd_URG_flag_count', 'fwd_pkts_payload_min', 'fwd_pkts_payload_max',\n",
      "       'fwd_pkts_payload_avg', 'fwd_pkts_payload_std', 'bwd_pkts_payload_max',\n",
      "       'bwd_pkts_payload_avg', 'bwd_pkts_payload_std', 'flow_pkts_payload_max',\n",
      "       'flow_pkts_payload_avg', 'flow_pkts_payload_std', 'fwd_iat_max',\n",
      "       'fwd_iat_avg', 'fwd_iat_std', 'flow_iat_max', 'flow_iat_avg',\n",
      "       'flow_iat_std', 'payload_bytes_per_second', 'fwd_subflow_pkts',\n",
      "       'bwd_subflow_pkts', 'fwd_subflow_bytes', 'active_min', 'active_max',\n",
      "       'active_avg', 'idle_min', 'idle_max', 'idle_avg',\n",
      "       'fwd_init_window_size', 'bwd_init_window_size', 'fwd_last_window_size'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "# Apply SelectKBest to the resampled training data\n",
    "selector = SelectKBest(score_func=f_classif, k=50)  \n",
    "X_train_kbest_under = selector.fit_transform(X_under, y_under)  \n",
    "\n",
    "# Transform the original test set using the fitted selector\n",
    "X_test_selected = selector.transform(X_test)  \n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_under.columns[selector.get_support()]  \n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Apply MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "X_train_kbest_scaled = scaler.fit_transform(X_train_kbest_under)  \n",
    "X_test_selected_scaled = scaler.transform(X_test_selected)  \n",
    "\n",
    "# Convert scaled arrays back to DataFrames for better readability\n",
    "X_train_kbest_scaled_under = pd.DataFrame(X_train_kbest_scaled, columns=selected_features)\n",
    "X_test_selected_scaled_under = pd.DataFrame(X_test_selected_scaled, columns=selected_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bb925c-3be6-473d-8b5e-8135882d9b49",
   "metadata": {},
   "source": [
    "##### Kbest for Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0c70e67c-1bf3-4f4d-a4cc-2f62a54450cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['id_orig_p', 'id_resp_p', 'proto', 'service', 'fwd_pkts_per_sec',\n",
      "       'bwd_pkts_per_sec', 'flow_pkts_per_sec', 'down_up_ratio',\n",
      "       'fwd_header_size_min', 'fwd_header_size_max', 'bwd_header_size_min',\n",
      "       'bwd_header_size_max', 'flow_FIN_flag_count', 'flow_SYN_flag_count',\n",
      "       'flow_RST_flag_count', 'fwd_URG_flag_count', 'fwd_pkts_payload_min',\n",
      "       'fwd_pkts_payload_max', 'fwd_pkts_payload_avg', 'fwd_pkts_payload_std',\n",
      "       'bwd_pkts_payload_min', 'bwd_pkts_payload_max', 'bwd_pkts_payload_avg',\n",
      "       'bwd_pkts_payload_std', 'flow_pkts_payload_min',\n",
      "       'flow_pkts_payload_max', 'flow_pkts_payload_avg',\n",
      "       'flow_pkts_payload_std', 'fwd_iat_max', 'fwd_iat_avg', 'fwd_iat_std',\n",
      "       'bwd_iat_max', 'bwd_iat_avg', 'bwd_iat_std', 'flow_iat_max',\n",
      "       'flow_iat_avg', 'flow_iat_std', 'payload_bytes_per_second',\n",
      "       'fwd_subflow_pkts', 'fwd_subflow_bytes', 'active_min', 'active_max',\n",
      "       'active_avg', 'active_std', 'idle_min', 'idle_max', 'idle_avg',\n",
      "       'fwd_init_window_size', 'bwd_init_window_size', 'fwd_last_window_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Apply SelectKBest to the resampled (SMOTE) training data\n",
    "selector = SelectKBest(score_func=f_classif, k=50)  \n",
    "X_kbest_smote = selector.fit_transform(X_smote, y_smote)  \n",
    "\n",
    "# Transform the original test set using the fitted selector\n",
    "X_test_selected = selector.transform(X_test)  \n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_smote.columns[selector.get_support()] \n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Apply MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "X_kbest_smote_scaled = scaler.fit_transform(X_kbest_smote) \n",
    "X_test_selected_scaled = scaler.transform(X_test_selected)  \n",
    "\n",
    "# Convert scaled arrays back to DataFrames for better readability\n",
    "X_kbest_smote_scaled = pd.DataFrame(X_kbest_smote_scaled, columns=selected_features)\n",
    "X_test_selected_scaled_smote = pd.DataFrame(X_test_selected_scaled, columns=selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaa80e1-ea26-4c8f-bae9-a7586c67348f",
   "metadata": {},
   "source": [
    "#### Kbest for Imbalanced Data (Starting Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "faf7ac64-1b15-47bf-b2df-876304ce1b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: Index(['id_orig_p', 'id_resp_p', 'proto', 'service', 'fwd_pkts_per_sec',\n",
      "       'bwd_pkts_per_sec', 'flow_pkts_per_sec', 'down_up_ratio',\n",
      "       'fwd_header_size_min', 'fwd_header_size_max', 'bwd_header_size_min',\n",
      "       'bwd_header_size_max', 'flow_FIN_flag_count', 'flow_SYN_flag_count',\n",
      "       'flow_RST_flag_count', 'fwd_PSH_flag_count', 'fwd_URG_flag_count',\n",
      "       'fwd_pkts_payload_min', 'fwd_pkts_payload_max', 'fwd_pkts_payload_avg',\n",
      "       'fwd_pkts_payload_std', 'bwd_pkts_payload_min', 'bwd_pkts_payload_max',\n",
      "       'bwd_pkts_payload_avg', 'bwd_pkts_payload_std', 'flow_pkts_payload_max',\n",
      "       'flow_pkts_payload_avg', 'flow_pkts_payload_std', 'fwd_iat_max',\n",
      "       'fwd_iat_tot', 'fwd_iat_avg', 'fwd_iat_std', 'bwd_iat_max',\n",
      "       'bwd_iat_avg', 'bwd_iat_std', 'flow_iat_max', 'flow_iat_tot',\n",
      "       'flow_iat_avg', 'flow_iat_std', 'payload_bytes_per_second',\n",
      "       'fwd_subflow_pkts', 'active_min', 'active_max', 'active_avg',\n",
      "       'idle_min', 'idle_max', 'idle_avg', 'fwd_init_window_size',\n",
      "       'bwd_init_window_size', 'fwd_last_window_size'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Apply SelectKBest to the original training data\n",
    "selector = SelectKBest(score_func = f_classif, k=50)  # Adjust 'k' as needed\n",
    "X_kbest_normal = selector.fit_transform(X_train, y_train)  \n",
    "\n",
    "# Transform the original test set using the fitted selector\n",
    "X_test_selected = selector.transform(X_test) \n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train.columns[selector.get_support()]  \n",
    "print(\"Selected features:\", selected_features)\n",
    "\n",
    "# Apply MinMaxScaler \n",
    "scaler = MinMaxScaler()\n",
    "X_kbest_normal_scaled = scaler.fit_transform(X_kbest_normal) \n",
    "X_test_selected_scaled = scaler.transform(X_test_selected)  \n",
    "\n",
    "# Convert scaled arrays back to DataFrames for better readability\n",
    "X_kbest_normal_scaled = pd.DataFrame(X_kbest_normal_scaled, columns=selected_features)\n",
    "X_test_selected_scaled_normal = pd.DataFrame(X_test_selected_scaled, columns=selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c083bfda-b346-412d-a2ce-606820366f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Data Integrity Check for Normal ---\n",
      "Column consistency:\n",
      "✓ Selected columns are consistent between X_train and X_test\n",
      "\n",
      "Checking for NaNs:\n",
      "✓ X_train has no missing values\n",
      "✓ X_test has no missing values\n",
      "✓ y_train has no missing values\n",
      "✓ y_test has no missing values\n",
      "\n",
      "Shape of data:\n",
      "X_train shape: (98493, 50)\n",
      "X_test shape: (24624, 50)\n",
      "y_train shape: (98493,)\n",
      "y_test shape: (24624,)\n",
      "\n",
      "--- Data Integrity Check for SMOTE ---\n",
      "Column consistency:\n",
      "✓ Selected columns are consistent between X_train and X_test\n",
      "\n",
      "Checking for NaNs:\n",
      "✓ X_train has no missing values\n",
      "✓ X_test has no missing values\n",
      "✓ y_train has no missing values\n",
      "✓ y_test has no missing values\n",
      "\n",
      "Shape of data:\n",
      "X_train shape: (908460, 50)\n",
      "X_test shape: (24624, 50)\n",
      "y_train shape: (98493,)\n",
      "y_test shape: (24624,)\n",
      "\n",
      "--- Data Integrity Check for Undersampled ---\n",
      "Column consistency:\n",
      "✓ Selected columns are consistent between X_train and X_test\n",
      "\n",
      "Checking for NaNs:\n",
      "✓ X_train has no missing values\n",
      "✓ X_test has no missing values\n",
      "✓ y_train has no missing values\n",
      "✓ y_test has no missing values\n",
      "\n",
      "Shape of data:\n",
      "X_train shape: (324, 50)\n",
      "X_test shape: (24624, 50)\n",
      "y_train shape: (98493,)\n",
      "y_test shape: (24624,)\n"
     ]
    }
   ],
   "source": [
    "# Import the function from functions.py\n",
    "from functions import check_data_integrity\n",
    "\n",
    "# Normal (original) data check\n",
    "check_data_integrity(X_kbest_normal_scaled, X_test_selected_scaled_normal, y_train, y_test, \"Normal\")\n",
    "\n",
    "# SMOTE data check\n",
    "check_data_integrity(X_kbest_smote_scaled, X_test_selected_scaled_smote, y_train, y_test, \"SMOTE\")\n",
    "\n",
    "# Undersampled data check\n",
    "check_data_integrity(X_train_kbest_scaled_under, X_test_selected_scaled_under, y_train, y_test, \"Undersampled\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb994d3a-77b5-4f75-807a-cf8d0849aa93",
   "metadata": {},
   "source": [
    "# ML Models with Normal Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ef4de2-ba27-4250-96aa-972e7488b5e8",
   "metadata": {},
   "source": [
    "#### Normal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ba6ecd6e-c0d5-4c8d-844e-7b63109c92c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9788\n",
      "Precision: 0.9793\n",
      "Recall: 0.9788\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82      1507\n",
      "           1       0.72      0.88      0.79       111\n",
      "           2       1.00      1.00      1.00     18954\n",
      "           3       1.00      1.00      1.00       849\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.98      1.00      0.99       384\n",
      "           7       1.00      0.99      1.00       171\n",
      "           8       0.96      0.98      0.97       524\n",
      "           9       1.00      1.00      1.00       420\n",
      "          10       0.82      0.94      0.88      1631\n",
      "          11       0.97      0.61      0.75        62\n",
      "\n",
      "    accuracy                           0.98     24624\n",
      "   macro avg       0.78      0.76      0.77     24624\n",
      "weighted avg       0.98      0.98      0.98     24624\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model using the normalized training data\n",
    "log_reg.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_norm = log_reg.predict(X_test_norm)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_norm)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred_norm, average='weighted')  \n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred_norm, average='weighted')  \n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_norm,))# target_names=['Class 0', 'Class 1'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62f34b-7f2c-4d2b-9bad-f108f6d7032f",
   "metadata": {},
   "source": [
    "#### Normal Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "87266027-9797-48bf-8063-902ece8b8d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9989\n",
      "Precision: 0.9989\n",
      "Recall: 0.9989\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1507\n",
      "           1       0.99      1.00      1.00       111\n",
      "           2       1.00      1.00      1.00     18954\n",
      "           3       1.00      1.00      1.00       849\n",
      "           4       1.00      1.00      1.00        10\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00       384\n",
      "           7       1.00      1.00      1.00       171\n",
      "           8       0.99      1.00      1.00       524\n",
      "           9       1.00      1.00      1.00       420\n",
      "          10       0.99      0.99      0.99      1631\n",
      "          11       1.00      0.94      0.97        62\n",
      "\n",
      "    accuracy                           1.00     24624\n",
      "   macro avg       1.00      0.99      1.00     24624\n",
      "weighted avg       1.00      1.00      1.00     24624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the normalized training data\n",
    "rf_model.fit(X_train_norm, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_norm_rf = rf_model.predict(X_test_norm)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_norm_rf)\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision_rf = precision_score(y_test, y_pred_norm_rf, average='weighted') \n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall_rf = recall_score(y_test, y_pred_norm_rf, average='weighted') \n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_norm_rf,))# target_names=['Class 0', 'Class 1']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5752b1-33ea-4529-b90e-c118f911aa37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65f2e911-1588-485f-ba10-3609cac8be76",
   "metadata": {},
   "source": [
    "# ML Models with Smote and Kbest Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d6323-c6fb-44e6-afd3-8096984c8ccd",
   "metadata": {},
   "source": [
    "##### Smote Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5c90a00d-16db-4d63-8d67-7ae1b3aa9492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825\n",
      "Precision: 0.9825\n",
      "Recall: 0.9825\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 1253    29     2     2    35     2     3     0     0     0   152    29]\n",
      " [    0   111     0     0     0     0     0     0     0     0     0     0]\n",
      " [    0     0 18954     0     0     0     0     0     0     0     0     0]\n",
      " [    3     0     0   845     0     1     0     0     0     0     0     0]\n",
      " [    0     0     0     0    10     0     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     1     0     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0   384     0     0     0     0     0]\n",
      " [    0     0     0     0     0     0     0   171     0     0     0     0]\n",
      " [    3    33     0     0     4     0     0     0   483     0     0     1]\n",
      " [    2     0     0     0     0     0     0     0     0   418     0     0]\n",
      " [   79     6     0     0    14     1     0     0     3     0  1507    21]\n",
      " [    2     0     1     0     0     0     1     0     0     0     1    57]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88      1507\n",
      "           1       0.62      1.00      0.77       111\n",
      "           2       1.00      1.00      1.00     18954\n",
      "           3       1.00      1.00      1.00       849\n",
      "           4       0.16      1.00      0.27        10\n",
      "           5       0.20      1.00      0.33         1\n",
      "           6       0.99      1.00      0.99       384\n",
      "           7       1.00      1.00      1.00       171\n",
      "           8       0.99      0.92      0.96       524\n",
      "           9       1.00      1.00      1.00       420\n",
      "          10       0.91      0.92      0.92      1631\n",
      "          11       0.53      0.92      0.67        62\n",
      "\n",
      "    accuracy                           0.98     24624\n",
      "   macro avg       0.78      0.97      0.82     24624\n",
      "weighted avg       0.99      0.98      0.98     24624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model using the SMOTE-resampled and scaled training data\n",
    "log_reg.fit(X_kbest_smote_scaled, y_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_smote = log_reg.predict(X_test_selected_scaled_smote)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred_smote)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred_smote, average='micro')  \n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred_smote, average='micro')  \n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Print the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_smote)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_smote))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea36a381-3644-4f55-8dd7-94a4f2f09f62",
   "metadata": {},
   "source": [
    "##### Smote Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e8c56300-6148-410e-8a37-cd2332b81090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 10, 11,  0,  1,  2,  4,  5,  6,  7,  8,  9])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Attack_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fa02a46b-0751-481c-9acc-99b6da6bd5e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Fit the model using the SMOTE-resampled and scaled training data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m rf_model\u001b[38;5;241m.\u001b[39mfit(X_kbest_smote_scaled, y_smote)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Predict on the test set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_pred_smote_rf \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_test_selected_scaled_smote)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    490\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    491\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    492\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    493\u001b[0m )(\n\u001b[1;32m    494\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    495\u001b[0m         t,\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[1;32m    497\u001b[0m         X,\n\u001b[1;32m    498\u001b[0m         y,\n\u001b[1;32m    499\u001b[0m         sample_weight,\n\u001b[1;32m    500\u001b[0m         i,\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[1;32m    502\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    503\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[1;32m    504\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[1;32m    505\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    506\u001b[0m     )\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    508\u001b[0m )\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    193\u001b[0m         X,\n\u001b[1;32m    194\u001b[0m         y,\n\u001b[1;32m    195\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39mcurr_sample_weight,\n\u001b[1;32m    196\u001b[0m         check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    197\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    198\u001b[0m     )\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m builder\u001b[38;5;241m.\u001b[39mbuild(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the SMOTE-resampled and scaled training data\n",
    "rf_model.fit(X_kbest_smote_scaled, y_smote)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_smote_rf = rf_model.predict(X_test_selected_scaled_smote)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_smote_rf)\n",
    "print(f\"Accuracy: {accuracy_rf:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision_rf = precision_score(y_test, y_pred_smote_rf, average='micro')\n",
    "print(f\"Precision: {precision_rf:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall_rf = recall_score(y_test, y_pred_smote_rf, average='micro')\n",
    "print(f\"Recall: {recall_rf:.4f}\")\n",
    "\n",
    "# Manually define the label mapping\n",
    "label_mapping = {\n",
    "    0: 'ARP_poisioning',\n",
    "    1: 'DDOS_Slowloris',\n",
    "    2: 'DOS_SYN_Hping',\n",
    "    3: 'MQTT_Publish',\n",
    "    4: 'Metasploit_Brute_Force_SSH',\n",
    "    5: 'NMAP_FIN_SCAN',\n",
    "    6: 'NMAP_OS_DETECTION',\n",
    "    7: 'NMAP_TCP_scan',\n",
    "    8: 'NMAP_UDP_SCAN',\n",
    "    9: 'NMAP_XMAS_TREE_SCAN',\n",
    "    10: 'Thing_Speak',\n",
    "    11: 'Wipro_bulb',}\n",
    "\n",
    "# Convert y_test and y_pred to their original class names using the manual mapping\n",
    "y_test_original = pd.Series(y_test).map(label_mapping)\n",
    "y_pred_original = pd.Series(y_pred_smote_rf).map(label_mapping)\n",
    "\n",
    "# Print the classification report with manually defined class names\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_original, y_pred_original))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix_rf = confusion_matrix(y_test_original, y_pred_original)\n",
    "\n",
    "# Plot the confusion matrix with manually defined class names\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix_rf, annot=True, fmt='d', cmap='Blues', xticklabels=list(label_mapping.values()), yticklabels=list(label_mapping.values()))\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix - Random Forest with Manually Defined Class Names')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6065fe-cff0-4848-837f-0815e6bfc3f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26857bf8-075f-464c-bcb5-b147f4d78d17",
   "metadata": {},
   "source": [
    "# ML Models with Undersampling and Kbest Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61acd7cc-89f7-48d4-a649-87de3b92fa8a",
   "metadata": {},
   "source": [
    "#### Under Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87406b61-0f98-4cff-884e-7031f3f056c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Logistic Regression model\n",
    "log_reg_under = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Fit the model using the scaled, feature-selected, undersampled training data\n",
    "log_reg_under.fit(X_train_kbest_scaled_under, y_under)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_under = log_reg_under.predict(X_test_selected_scaled_under)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_under = accuracy_score(y_test, y_pred_under)\n",
    "print(f\"Accuracy: {accuracy_under:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision_under = precision_score(y_test, y_pred_under, average='weighted')  \n",
    "print(f\"Precision: {precision_under:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall_under = recall_score(y_test, y_pred_under, average='weighted')  \n",
    "print(f\"Recall: {recall_under:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_under,))# target_names=['Class 0', 'Class 1'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379488ac-8e1c-48d3-a012-b76c345e1de2",
   "metadata": {},
   "source": [
    "#### Under Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ecad20-373a-47f2-b2ea-c8d9434affc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest model\n",
    "rf_model_under = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Fit the model using the scaled, feature-selected, undersampled training data\n",
    "rf_model_under.fit(X_train_kbest_scaled_under, y_under)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_under_rf = rf_model_under.predict(X_test_selected_scaled_under)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_under_rf = accuracy_score(y_test, y_pred_under_rf)\n",
    "print(f\"Accuracy: {accuracy_under_rf:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision_under_rf = precision_score(y_test, y_pred_under_rf, average='weighted')  \n",
    "print(f\"Precision: {precision_under_rf:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall_under_rf = recall_score(y_test, y_pred_under_rf, average='weighted') \n",
    "print(f\"Recall: {recall_under_rf:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_under_rf, ))#target_names=['Class 0', 'Class 1'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ab38d4-87a1-4d90-acf6-102a57140431",
   "metadata": {},
   "source": [
    "#### Under SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bc10a8-dd15-410f-9b01-57f1fb50b86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model_under = SVC(random_state=42, kernel='rbf')  # You can change 'kernel' to 'linear', 'poly', or 'sigmoid' as needed\n",
    "\n",
    "# Fit the model using the scaled, feature-selected, undersampled training data\n",
    "svm_model_under.fit(X_train_kbest_scaled_under, y_under)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_under_svm = svm_model_under.predict(X_test_selected_scaled_under)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_under_svm = accuracy_score(y_test, y_pred_under_svm)\n",
    "print(f\"Accuracy: {accuracy_under_svm:.4f}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision_under_svm = precision_score(y_test, y_pred_under_svm, average='weighted')  # Adjust 'binary' for multiclass\n",
    "print(f\"Precision: {precision_under_svm:.4f}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall_under_svm = recall_score(y_test, y_pred_under_svm, average='weighted')  # Adjust 'binary' for multiclass\n",
    "print(f\"Recall: {recall_under_svm:.4f}\")\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_under_svm,))# target_names=['Class 0', 'Class 1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03ab4e6-4e17-4659-ae8b-0bb5480a6d8a",
   "metadata": {},
   "source": [
    "We are going to go with the Smote Random forest model, as that seems to be the best one. We dont need to enhance it with Random Search or Gridsearch or Hypertuning as it is alredy good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21972fa0-b310-4d82-bb4e-b67073b581d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoblib\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Save the model to a file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(rf_model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_forest_model_smote.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save the scaler to a .joblib file\u001b[39;00m\n\u001b[1;32m      6\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(scaler, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_model' is not defined"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(rf_model, 'random_forest_model_smote.joblib')\n",
    "# Save the scaler to a .joblib file\n",
    "joblib.dump(scaler, 'scaler.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ff73b-b842-4cfe-bd90-2ea2efd2e455",
   "metadata": {},
   "source": [
    "# Simulating IoT Datafeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233d9067-a8a7-4303-a4fc-07f113990115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "29a47e5e-beeb-4ded-9da5-87a3968e6b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_column_names(X_test_selected_scaled_smote):\n",
    "    # Get the column names from the DataFrame or array\n",
    "    if hasattr(X_test_selected_scaled_smote, 'columns'):\n",
    "        # If it's a DataFrame, return column names\n",
    "        return X_test_selected_scaled_smote.columns.tolist()\n",
    "    else:\n",
    "        # If it's a numpy array, you may need to access column names if available\n",
    "        return [\"Column_\" + str(i) for i in range(X_test_selected_scaled_smote.shape[1])]\n",
    "\n",
    "# Get column names from the DataFrame or array\n",
    "column_names = get_column_names(X_test_selected_scaled_smote)\n",
    "\n",
    "# Convert the column names list into a DataFrame (with one row to view)\n",
    "column_names_df = pd.DataFrame([column_names], columns=column_names)\n",
    "\n",
    "# Save column names used during training\n",
    "feature_names = column_names_df.columns.tolist()  \n",
    "joblib.dump(feature_names, 'feature_names.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c3872256-dab4-4fb6-9b34-c72e62baa393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_orig_p</th>\n",
       "      <th>id_resp_p</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>fwd_pkts_per_sec</th>\n",
       "      <th>bwd_pkts_per_sec</th>\n",
       "      <th>flow_pkts_per_sec</th>\n",
       "      <th>down_up_ratio</th>\n",
       "      <th>fwd_header_size_min</th>\n",
       "      <th>fwd_header_size_max</th>\n",
       "      <th>...</th>\n",
       "      <th>active_min</th>\n",
       "      <th>active_max</th>\n",
       "      <th>active_avg</th>\n",
       "      <th>active_std</th>\n",
       "      <th>idle_min</th>\n",
       "      <th>idle_max</th>\n",
       "      <th>idle_avg</th>\n",
       "      <th>fwd_init_window_size</th>\n",
       "      <th>bwd_init_window_size</th>\n",
       "      <th>fwd_last_window_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_orig_p</td>\n",
       "      <td>id_resp_p</td>\n",
       "      <td>proto</td>\n",
       "      <td>service</td>\n",
       "      <td>fwd_pkts_per_sec</td>\n",
       "      <td>bwd_pkts_per_sec</td>\n",
       "      <td>flow_pkts_per_sec</td>\n",
       "      <td>down_up_ratio</td>\n",
       "      <td>fwd_header_size_min</td>\n",
       "      <td>fwd_header_size_max</td>\n",
       "      <td>...</td>\n",
       "      <td>active_min</td>\n",
       "      <td>active_max</td>\n",
       "      <td>active_avg</td>\n",
       "      <td>active_std</td>\n",
       "      <td>idle_min</td>\n",
       "      <td>idle_max</td>\n",
       "      <td>idle_avg</td>\n",
       "      <td>fwd_init_window_size</td>\n",
       "      <td>bwd_init_window_size</td>\n",
       "      <td>fwd_last_window_size</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
       "0  id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec   \n",
       "\n",
       "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
       "0  flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max   \n",
       "\n",
       "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
       "0  ...  active_min  active_max  active_avg  active_std  idle_min  idle_max   \n",
       "\n",
       "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
       "0  idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e68cef4f-4239-4b09-a865-41fc24644d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "rf_model = joblib.load('random_forest_model_smote.joblib')\n",
    "# Load the scaler from the .joblib file\n",
    "scaler = joblib.load('scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5a49f0c-59ea-4951-a4cb-e760840b81a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Adjusted real-time prediction function \n",
    "def real_time_prediction_from_df(row):\n",
    "    import time\n",
    "    # Convert the row to a DataFrame format to maintain compatibility\n",
    "    new_data_df = pd.DataFrame([row], columns=X_test_selected_scaled_smote.columns)\n",
    "    \n",
    "    # Normalize the new data using the existing MinMaxScaler\n",
    "    new_data_scaled = scaler.transform(new_data_df)  # Ensure consistent scaling\n",
    "    \n",
    "    # Predict using the trained RandomForest model\n",
    "    prediction = rf_model.predict(new_data_scaled)\n",
    "    \n",
    "    # Return the prediction label\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3bc2fa3-fa11-4e7f-9bb7-c9d14662d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to shuffle and simulate real-time data feeding with row and probability printing\n",
    "def simulate_real_time_feed_from_df(df, delay=1):\n",
    "    # Shuffle the DataFrame to randomize row order\n",
    "    shuffled_df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    for _, row in shuffled_df.iterrows():\n",
    "        # Drop the 'Attack_type' or any target columns for prediction\n",
    "        new_data_row = row.drop(['Attack_type', 'Attack'], errors='ignore')\n",
    "\n",
    "        # Align with the feature columns used in training (X_test_selected_scaled_smote.columns)\n",
    "        new_data_row = pd.DataFrame([new_data_row], columns= column_names_df.columns) #X_test_selected_scaled_smote\n",
    "\n",
    "        # Initialize the LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Apply LabelEncoder to each categorical column\n",
    "        for column in new_data_row.columns:\n",
    "            if new_data_row[column].dtype == 'object' or new_data_row[column].dtype.name == 'category':\n",
    "                new_data_row[column] = label_encoder.fit_transform(new_data_row[column]) \n",
    "\n",
    "        \n",
    "        # Print the row's feature values before scaling and encoding\n",
    "        print(\"\\nFeature Values (Raw):\")\n",
    "        print(new_data_row)\n",
    "\n",
    "        # Apply scaling to the row\n",
    "        new_data_scaled = scaler.transform(new_data_row)\n",
    "        new_data_scaled_df = pd.DataFrame(new_data_scaled, columns= column_names_df.columns) #X_test_selected_scaled_smote\n",
    "\n",
    "        # Print the row's feature values after scaling\n",
    "        #print(\"\\nFeature Values (Scaled):\")\n",
    "        #print(new_data_scaled_df)\n",
    "\n",
    "        # Get the prediction and probabilities\n",
    "        prediction = rf_model.predict(new_data_scaled_df)\n",
    "        prediction_proba = rf_model.predict_proba(new_data_scaled_df)\n",
    "\n",
    "        # Convert numeric prediction to original class name using the manual label mapping\n",
    "        prediction_label = label_mapping.get(prediction[0], \"Unknown\")\n",
    "\n",
    "        # Print the prediction result and probabilities\n",
    "        print(f\"\\nPredicted Attack Type: {prediction_label}\")\n",
    "        print(f\"Prediction Probabilities: {prediction_proba[0]}\")\n",
    "        \n",
    "        # Simulate real-time delay\n",
    "        time.sleep(delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0e173dbc-1e5f-40e9-939a-787b87fcecb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Attack_type\n",
       "2     94659\n",
       "10     8108\n",
       "0      7750\n",
       "3      4146\n",
       "8      2590\n",
       "9      2010\n",
       "6      2000\n",
       "7      1002\n",
       "1       534\n",
       "11      253\n",
       "4        37\n",
       "5        28\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Attack_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd0e88d0-d981-4981-a571-7c52aeda9779",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    0: 'ARP_poisioning',\n",
    "    1: 'DDOS_Slowloris',\n",
    "    2: 'DOS_SYN_Hping',\n",
    "    3: 'MQTT_Publish',\n",
    "    4: 'Metasploit_Brute_Force_SSH',\n",
    "    5: 'NMAP_FIN_SCAN',\n",
    "    6: 'NMAP_OS_DETECTION',\n",
    "    7: 'NMAP_TCP_scan',\n",
    "    8: 'NMAP_UDP_SCAN',\n",
    "    9: 'NMAP_XMAS_TREE_SCAN',\n",
    "    10: 'Thing_Speak',\n",
    "    11: 'Wipro_bulb',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "114dd784-7aea-482a-b604-8132b5d6a0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "0     7315.0       21.0    1.0      0.0          838860.8          838860.8   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "0          1677721.6            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "0  ...    1.192093    1.192093    1.192093         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "0       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.02 0.   0.85 0.01 0.   0.   0.03 0.   0.02 0.   0.04 0.03]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "1    18609.0       21.0    1.0      0.0          262144.0          262144.0   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "1           524288.0            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "1  ...    3.814697    3.814697    3.814697         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "1       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.02 0.   0.84 0.01 0.   0.   0.03 0.   0.02 0.   0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "2    14663.0       21.0    1.0      0.0     466033.777778     466033.777778   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "2      932067.555556            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "2  ...    2.145767    2.145767    2.145767         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "2       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.02 0.   0.84 0.01 0.   0.   0.03 0.   0.02 0.   0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "3    37827.0     1883.0    1.0      5.0          0.145039          0.080577   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "3           0.225616       0.555556                 32.0                 40.0   \n",
      "\n",
      "   ...    active_min    active_max    active_avg  active_std      idle_min  \\\n",
      "3  ...  2.233347e+06  2.233347e+06  2.233347e+06         0.0  5.981909e+07   \n",
      "\n",
      "       idle_max      idle_avg  fwd_init_window_size  bwd_init_window_size  \\\n",
      "3  5.981909e+07  5.981909e+07               64240.0               26847.0   \n",
      "\n",
      "   fwd_last_window_size  \n",
      "3                 502.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: MQTT_Publish\n",
      "Prediction Probabilities: [0.08 0.02 0.   0.76 0.   0.   0.   0.   0.01 0.   0.11 0.02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "4    22348.0       21.0    1.0      0.0               0.0               0.0   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "4                0.0            0.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "4  ...         0.0         0.0         0.0         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "4       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.05 0.01 0.72 0.   0.   0.04 0.   0.   0.02 0.03 0.08 0.05]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "5    37150.0       21.0    1.0      0.0     199728.761905     199728.761905   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "5       399457.52381            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "5  ...     5.00679     5.00679     5.00679         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "5       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.02 0.   0.84 0.02 0.   0.   0.02 0.   0.02 0.   0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "6    36115.0       21.0    1.0      0.0     199728.761905     199728.761905   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "6       399457.52381            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "6  ...     5.00679     5.00679     5.00679         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "6       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.02 0.   0.84 0.02 0.   0.   0.02 0.   0.02 0.   0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "7    42253.0       21.0    1.0      0.0     246723.764706     246723.764706   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "7      493447.529412            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "7  ...    4.053116    4.053116    4.053116         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "7       0.0                  64.0                   0.0                  64.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: DOS_SYN_Hping\n",
      "Prediction Probabilities: [0.01 0.   0.84 0.02 0.   0.   0.03 0.   0.02 0.   0.04 0.04]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "8    36242.0     1334.0    1.0      0.0     110376.421053     110376.421053   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "8      220752.842105            1.0                 20.0                 20.0   \n",
      "\n",
      "   ...  active_min  active_max  active_avg  active_std  idle_min  idle_max  \\\n",
      "8  ...    9.059906    9.059906    9.059906         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "8       0.0                1024.0                   0.0                1024.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: NMAP_OS_DETECTION\n",
      "Prediction Probabilities: [0.03       0.         0.         0.03       0.         0.\n",
      " 0.55155702 0.         0.         0.35844298 0.         0.03      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature Values (Raw):\n",
      "   id_orig_p  id_resp_p  proto  service  fwd_pkts_per_sec  bwd_pkts_per_sec  \\\n",
      "9    49275.0       53.0    2.0      2.0         93.601964         93.601964   \n",
      "\n",
      "   flow_pkts_per_sec  down_up_ratio  fwd_header_size_min  fwd_header_size_max  \\\n",
      "9         187.203928            1.0                  8.0                  8.0   \n",
      "\n",
      "   ...   active_min   active_max   active_avg  active_std  idle_min  idle_max  \\\n",
      "9  ...  21367.07306  21367.07306  21367.07306         0.0       0.0       0.0   \n",
      "\n",
      "   idle_avg  fwd_init_window_size  bwd_init_window_size  fwd_last_window_size  \n",
      "9       0.0                   0.0                   0.0                   0.0  \n",
      "\n",
      "[1 rows x 50 columns]\n",
      "\n",
      "Predicted Attack Type: Thing_Speak\n",
      "Prediction Probabilities: [0.23 0.01 0.05 0.01 0.04 0.01 0.   0.   0.1  0.   0.46 0.09]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:486: UserWarning: X has feature names, but MinMaxScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Call the function with your DataFrame\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m simulate_real_time_feed_from_df(df, delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 46\u001b[0m, in \u001b[0;36msimulate_real_time_feed_from_df\u001b[0;34m(df, delay)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction Probabilities: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprediction_proba[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Simulate real-time delay\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(delay)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Call the function with your DataFrame\n",
    "simulate_real_time_feed_from_df(df, delay=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70be1bf3-c444-43c7-856e-97b0cc3d1ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "  Downloading shap-0.46.0-cp312-cp312-macosx_10_9_x86_64.whl.metadata (24 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.26.4)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from shap) (1.4.2)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from shap) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in /opt/anaconda3/lib/python3.12/site-packages (from shap) (4.66.4)\n",
      "Requirement already satisfied: packaging>20.9 in /opt/anaconda3/lib/python3.12/site-packages (from shap) (23.2)\n",
      "Collecting slicer==0.0.8 (from shap)\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: numba in /opt/anaconda3/lib/python3.12/site-packages (from shap) (0.59.1)\n",
      "Requirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.12/site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/anaconda3/lib/python3.12/site-packages (from numba->shap) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->shap) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->shap) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
      "Downloading shap-0.46.0-cp312-cp312-macosx_10_9_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.3/459.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: slicer, shap\n",
      "Successfully installed shap-0.46.0 slicer-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c22195-6c9e-4590-aad0-393e23df9891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
